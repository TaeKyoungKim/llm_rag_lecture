# ì‹¤ì œ PDF íŒŒì¼ì„ ë¡œë“œí•˜ê³  ì²˜ë¦¬í•˜ëŠ” ì£¼ì‹ ê¸°ìˆ ì  ë¶„ì„ ì‹œìŠ¤í…œ

# í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜
# uv add langchain_community pypdf rapidocr-onnxruntime pytesseract pandas requests

import os
import re
import requests
import pandas as pd
from datetime import datetime
from pathlib import Path
from typing import List, Dict, Optional, Any

# LangChain PDF ë¡œë”
from langchain_community.document_loaders import PyPDFLoader
from langchain_community.document_loaders.generic import GenericLoader
from langchain_community.document_loaders import FileSystemBlobLoader
from langchain_community.document_loaders.parsers import PyPDFParser
from langchain_community.document_loaders.parsers import RapidOCRBlobParser, TesseractBlobParser

print("ğŸ”§ ì‹¤ì œ PDF íŒŒì¼ ì²˜ë¦¬ ì‹œìŠ¤í…œ ì´ˆê¸°í™”")
print("=" * 60)

class RealPDFProcessor:
    """ì‹¤ì œ PDF íŒŒì¼ì„ ì²˜ë¦¬í•˜ëŠ” í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.pdf_path = Path("DocumentsLoader/data/ê¸°ìˆ ì ì°¨íŠ¸ë¶„ì„ì´ë¡ ë°ë°©ë²•.pdf")
        
        # ê¸°ìˆ ì  ë¶„ì„ í‚¤ì›Œë“œ (í•œêµ­ì–´ + ì˜ì–´)
        self.technical_keywords = {
            'indicators': [
                'RSI', 'ìƒëŒ€ê°•ë„ì§€ìˆ˜', 'MACD', 'ì´ë™í‰ê· ìˆ˜ë ´í™•ì‚°',
                'ë³¼ë¦°ì €ë°´ë“œ', 'Bollinger', 'ìŠ¤í† ìºìŠ¤í‹±', 'Stochastic',
                'ATR', 'CCI', 'Williams %R', 'ì´ë™í‰ê· ', 'Moving Average',
                'KDJ', 'DMI', 'OBV', 'VR', 'ROC', 'MOM', 'ADX'
            ],
            'patterns': [
                'ì‚¼ê°í˜•', 'ìê¸°í˜•', 'í”Œë˜ê·¸', 'í—¤ë“œì•¤ìˆ„ë”', 'ë”ë¸”íƒ‘', 'ë”ë¸”ë°”í…€',
                'ì»µì•¤í•¸ë“¤', 'ì—­í—¤ë“œì•¤ìˆ„ë”', 'ìƒìŠ¹ì‚¼ê°í˜•', 'í•˜ë½ì‚¼ê°í˜•',
                'Triangle', 'Wedge', 'Flag', 'Head and Shoulders', 'Double Top', 'Double Bottom',
                'Cup and Handle', 'Inverse Head and Shoulders'
            ],
            'concepts': [
                'ì§€ì§€ì„ ', 'ì €í•­ì„ ', 'ì¶”ì„¸ì„ ', 'ê³¼ë§¤ìˆ˜', 'ê³¼ë§¤ë„', 'ë‹¤ì´ë²„ì „ìŠ¤',
                'í¬ë¡œìŠ¤ì˜¤ë²„', 'ë¸Œë ˆì´í¬ì•„ì›ƒ', 'í’€ë°±', 'ë˜ëŒë¦¼', 'ê³¨ë“ í¬ë¡œìŠ¤', 'ë°ë“œí¬ë¡œìŠ¤',
                'Support', 'Resistance', 'Trend', 'Overbought', 'Oversold', 'Divergence',
                'Crossover', 'Breakout', 'Pullback', 'Retracement'
            ],
            'levels': [
                '30', '70', '50', '20', '80', '0.618', '0.382', '1.618',
                '0.236', '0.5', '0.786', '1.0', '1.272', '1.414', '2.0'
            ]
        }
    
    def check_pdf_exists(self) -> bool:
        """PDF íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸"""
        if self.pdf_path.exists():
            print(f"âœ… PDF íŒŒì¼ ë°œê²¬: {self.pdf_path}")
            print(f"   íŒŒì¼ í¬ê¸°: {self.pdf_path.stat().st_size / 1024:.1f} KB")
            return True
        else:
            print(f"âŒ PDF íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {self.pdf_path}")
            return False
    
    def load_pdf_with_pypdf(self) -> Optional[List]:
        """PyPDFLoaderë¥¼ ì‚¬ìš©í•˜ì—¬ PDF ë¡œë“œ"""
        try:
            print(f"\nğŸ“„ PyPDFLoaderë¡œ PDF ë¡œë“œ ì¤‘...")
            print(f"   íŒŒì¼ ê²½ë¡œ: {self.pdf_path}")
            
            loader = PyPDFLoader(str(self.pdf_path))
            docs = loader.load()
            
            print(f"   âœ… PDF ë¡œë“œ ì„±ê³µ!")
            print(f"   ğŸ“Š ë¬¸ì„œ ì •ë³´:")
            print(f"      - ì´ ë¬¸ì„œ ìˆ˜: {len(docs)}ê°œ")
            
            for i, doc in enumerate(docs[:3]):  # ì²˜ìŒ 3ê°œ ë¬¸ì„œë§Œ í‘œì‹œ
                print(f"      - ë¬¸ì„œ {i+1}: {len(doc.page_content)}ì")
                if doc.metadata:
                    print(f"        ë©”íƒ€ë°ì´í„°: {doc.metadata}")
            
            if len(docs) > 3:
                print(f"      - ... ì™¸ {len(docs) - 3}ê°œ ë¬¸ì„œ")
            
            return docs
            
        except Exception as e:
            print(f"   âŒ PDF ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
            return None
    
    def load_pdf_with_generic_loader(self) -> Optional[List]:
        """GenericLoaderë¥¼ ì‚¬ìš©í•˜ì—¬ PDF ë¡œë“œ (ê³ ê¸‰ ê¸°ëŠ¥)"""
        try:
            print(f"\nğŸ“„ GenericLoaderë¡œ PDF ë¡œë“œ ì¤‘...")
            
            # FileSystemBlobLoaderì™€ PyPDFParser ì¡°í•©
            loader = GenericLoader.from_filesystem(
                path=str(self.pdf_path.parent),
                glob=f"**/{self.pdf_path.name}",
                parser=PyPDFParser()
            )
            docs = loader.load()
            
            print(f"   âœ… GenericLoader ë¡œë“œ ì„±ê³µ!")
            print(f"   ğŸ“Š ë¬¸ì„œ ìˆ˜: {len(docs)}ê°œ")
            
            return docs
            
        except Exception as e:
            print(f"   âŒ GenericLoader ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
            return None
    
    def extract_technical_indicators(self, content: str) -> Dict[str, Any]:
        """ê¸°ìˆ ì  ë¶„ì„ ì§€í‘œ ì¶”ì¶œ"""
        extracted_info = {
            'indicators_found': [],
            'patterns_found': [],
            'concepts_found': [],
            'numeric_levels': [],
            'analysis_summary': {}
        }
        
        content_lower = content.lower()
        
        # ì§€í‘œ ê²€ìƒ‰
        for category, keywords in self.technical_keywords.items():
            found_items = []
            for keyword in keywords:
                # ëŒ€ì†Œë¬¸ì êµ¬ë¶„ ì—†ì´ ê²€ìƒ‰
                if keyword.lower() in content_lower or keyword in content:
                    found_items.append(keyword)
            
            if category == 'levels':
                extracted_info['numeric_levels'] = found_items
            else:
                extracted_info[f'{category[:-1]}_found'] = found_items
        
        # ë¶„ì„ ìš”ì•½ ìƒì„±
        total_indicators = len(extracted_info['indicators_found'])
        total_patterns = len(extracted_info['patterns_found'])
        total_concepts = len(extracted_info['concepts_found'])
        
        extracted_info['analysis_summary'] = {
            'total_indicators': total_indicators,
            'total_patterns': total_patterns,
            'total_concepts': total_concepts,
            'content_quality_score': min(100, (total_indicators * 10) + (total_patterns * 5) + (total_concepts * 3)),
            'main_focus': self._determine_main_focus(extracted_info)
        }
        
        return extracted_info
    
    def _determine_main_focus(self, extracted_info: Dict) -> str:
        """ì£¼ìš” í¬ì»¤ìŠ¤ ê²°ì •"""
        indicators = extracted_info['indicators_found']
        
        if any('RSI' in ind or 'ìƒëŒ€ê°•ë„' in ind for ind in indicators):
            if any('MACD' in ind or 'ì´ë™í‰ê· ìˆ˜ë ´' in ind for ind in indicators):
                return "RSI + MACD ë³µí•© ë¶„ì„"
            return "RSI ì¤‘ì‹¬ ë¶„ì„"
        elif any('MACD' in ind or 'ì´ë™í‰ê· ìˆ˜ë ´' in ind for ind in indicators):
            return "MACD ì¤‘ì‹¬ ë¶„ì„"
        elif any('ë³¼ë¦°ì €' in ind or 'Bollinger' in ind for ind in indicators):
            return "ë³¼ë¦°ì €ë°´ë“œ ì¤‘ì‹¬ ë¶„ì„"
        else:
            return "ì¼ë°˜ ê¸°ìˆ ì  ë¶„ì„"
    
    def analyze_pdf_content(self, docs: List) -> Dict[str, Any]:
        """PDF ë‚´ìš© ì¢…í•© ë¶„ì„"""
        print(f"\nğŸ” PDF ë‚´ìš© ë¶„ì„ ì¤‘...")
        
        # ëª¨ë“  ë¬¸ì„œ ë‚´ìš© í•©ì¹˜ê¸°
        full_content = ""
        for i, doc in enumerate(docs):
            full_content += f"\n--- í˜ì´ì§€ {i+1} ---\n"
            full_content += doc.page_content
            full_content += "\n"
        
        print(f"   ğŸ“ ì´ í…ìŠ¤íŠ¸ ê¸¸ì´: {len(full_content):,}ì")
        
        # ê¸°ìˆ ì  ë¶„ì„ ì§€í‘œ ì¶”ì¶œ
        analysis_results = self.extract_technical_indicators(full_content)
        
        return {
            'full_content': full_content,
            'analysis_results': analysis_results,
            'document_count': len(docs)
        }
    
    def generate_detailed_report(self, analysis_data: Dict):
        """ìƒì„¸ ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„±"""
        print(f"\nğŸ“ˆ ê¸°ìˆ ì  ë¶„ì„ PDF ìƒì„¸ ë¦¬í¬íŠ¸")
        print("=" * 60)
        
        # ê¸°ë³¸ ì •ë³´
        print(f"\nğŸ“„ PDF ê¸°ë³¸ ì •ë³´:")
        print(f"   â€¢ íŒŒì¼ëª…: {self.pdf_path.name}")
        print(f"   â€¢ ë¬¸ì„œ ìˆ˜: {analysis_data['document_count']}ê°œ")
        print(f"   â€¢ ì´ í…ìŠ¤íŠ¸ ê¸¸ì´: {len(analysis_data['full_content']):,}ì")
        
        # ê¸°ìˆ ì  ë¶„ì„ ë‚´ìš© ì¶”ì¶œ ê²°ê³¼
        analysis_results = analysis_data['analysis_results']
        summary = analysis_results['analysis_summary']
        
        print(f"\nğŸ” ê¸°ìˆ ì  ë¶„ì„ ë‚´ìš© ì¶”ì¶œ ê²°ê³¼:")
        print(f"   â€¢ ë°œê²¬ëœ ê¸°ìˆ  ì§€í‘œ: {summary['total_indicators']}ê°œ")
        if analysis_results['indicators_found']:
            print(f"     â†’ {', '.join(analysis_results['indicators_found'][:10])}")
            if len(analysis_results['indicators_found']) > 10:
                print(f"     â†’ ... ì™¸ {len(analysis_results['indicators_found']) - 10}ê°œ")
        
        print(f"   â€¢ ë°œê²¬ëœ íŒ¨í„´: {summary['total_patterns']}ê°œ")
        if analysis_results['patterns_found']:
            print(f"     â†’ {', '.join(analysis_results['patterns_found'])}")
        
        print(f"   â€¢ ë°œê²¬ëœ ê°œë…: {summary['total_concepts']}ê°œ")
        if analysis_results['concepts_found']:
            print(f"     â†’ {', '.join(analysis_results['concepts_found'][:10])}")
            if len(analysis_results['concepts_found']) > 10:
                print(f"     â†’ ... ì™¸ {len(analysis_results['concepts_found']) - 10}ê°œ")
        
        print(f"   â€¢ ì£¼ìš” í¬ì»¤ìŠ¤: {summary['main_focus']}")
        print(f"   â€¢ ë‚´ìš© í’ˆì§ˆ ì ìˆ˜: {summary['content_quality_score']}/100")
        
        # í’ˆì§ˆ ë“±ê¸‰
        score = summary['content_quality_score']
        if score >= 80:
            grade = "ğŸ¥‡ ìµœìš°ìˆ˜ (ì „ë¬¸ ìˆ˜ì¤€)"
        elif score >= 60:
            grade = "ğŸ¥ˆ ìš°ìˆ˜ (ì‹¤ìš© ìˆ˜ì¤€)"
        elif score >= 40:
            grade = "ğŸ¥‰ ì–‘í˜¸ (ê¸°ì´ˆ ìˆ˜ì¤€)"
        else:
            grade = "ğŸ“ ê¸°ë³¸ (ì…ë¬¸ ìˆ˜ì¤€)"
        
        print(f"   â€¢ í’ˆì§ˆ ë“±ê¸‰: {grade}")
        
        # ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°
        print(f"\nğŸ“– ë‚´ìš© ë¯¸ë¦¬ë³´ê¸° (ì²˜ìŒ 500ì):")
        preview = analysis_data['full_content'][:500]
        print(f"   {preview}...")
        
        return analysis_results
    
    def save_analysis_results(self, analysis_data: Dict, output_file: str = "technical_analysis_results.txt"):
        """ë¶„ì„ ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥"""
        try:
            with open(output_file, 'w', encoding='utf-8') as f:
                f.write("ê¸°ìˆ ì  ë¶„ì„ PDF ì²˜ë¦¬ ê²°ê³¼\n")
                f.write("=" * 50 + "\n\n")
                
                f.write(f"íŒŒì¼ëª…: {self.pdf_path.name}\n")
                f.write(f"ì²˜ë¦¬ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write(f"ë¬¸ì„œ ìˆ˜: {analysis_data['document_count']}ê°œ\n")
                f.write(f"ì´ í…ìŠ¤íŠ¸ ê¸¸ì´: {len(analysis_data['full_content']):,}ì\n\n")
                
                analysis_results = analysis_data['analysis_results']
                summary = analysis_results['analysis_summary']
                
                f.write("ë°œê²¬ëœ ê¸°ìˆ  ì§€í‘œ:\n")
                for indicator in analysis_results['indicators_found']:
                    f.write(f"  - {indicator}\n")
                f.write("\n")
                
                f.write("ë°œê²¬ëœ íŒ¨í„´:\n")
                for pattern in analysis_results['patterns_found']:
                    f.write(f"  - {pattern}\n")
                f.write("\n")
                
                f.write("ë°œê²¬ëœ ê°œë…:\n")
                for concept in analysis_results['concepts_found']:
                    f.write(f"  - {concept}\n")
                f.write("\n")
                
                f.write(f"ì£¼ìš” í¬ì»¤ìŠ¤: {summary['main_focus']}\n")
                f.write(f"í’ˆì§ˆ ì ìˆ˜: {summary['content_quality_score']}/100\n\n")
                
                f.write("ì „ì²´ ë‚´ìš©:\n")
                f.write("-" * 30 + "\n")
                f.write(analysis_data['full_content'])
            
            print(f"   âœ… ë¶„ì„ ê²°ê³¼ê°€ {output_file}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
            
        except Exception as e:
            print(f"   âŒ íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {str(e)}")
    
    def process_pdf(self):
        """PDF ì²˜ë¦¬ ë©”ì¸ í•¨ìˆ˜"""
        print("ğŸš€ PDF ì²˜ë¦¬ ì‹œì‘")
        print("=" * 60)
        
        # 1. PDF íŒŒì¼ ì¡´ì¬ í™•ì¸
        if not self.check_pdf_exists():
            return None
        
        # 2. PyPDFLoaderë¡œ PDF ë¡œë“œ
        docs = self.load_pdf_with_pypdf()
        if not docs:
            print("âŒ PDF ë¡œë“œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
            return None
        
        # 3. PDF ë‚´ìš© ë¶„ì„
        analysis_data = self.analyze_pdf_content(docs)
        
        # 4. ìƒì„¸ ë¦¬í¬íŠ¸ ìƒì„±
        analysis_results = self.generate_detailed_report(analysis_data)
        
        # 5. ê²°ê³¼ ì €ì¥
        self.save_analysis_results(analysis_data)
        
        return analysis_data

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    processor = RealPDFProcessor()
    result = processor.process_pdf()
    
    if result:
        print(f"\nğŸ‰ PDF ì²˜ë¦¬ ì™„ë£Œ!")
        print(f"   ğŸ“Š ì´ {result['document_count']}ê°œ ë¬¸ì„œ ì²˜ë¦¬")
        print(f"   ğŸ“ {len(result['full_content']):,}ì í…ìŠ¤íŠ¸ ì¶”ì¶œ")
        print(f"   ğŸ” {result['analysis_results']['analysis_summary']['total_indicators']}ê°œ ê¸°ìˆ  ì§€í‘œ ë°œê²¬")
    else:
        print(f"\nâŒ PDF ì²˜ë¦¬ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    main() 
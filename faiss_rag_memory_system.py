"""
FAISS RAG ì‹œìŠ¤í…œ + ëŒ€í™” ë©”ëª¨ë¦¬ í†µí•©
FAISS ë¬¸ì„œ ê²€ìƒ‰ + ëŒ€í™” ê¸°ë¡ ê¸°ì–µ ê¸°ëŠ¥
"""

import os
import json
import numpy as np
from datetime import datetime
from pathlib import Path
from typing import List, Dict, Any, Optional

# FAISS ë° LangChain ë¼ì´ë¸ŒëŸ¬ë¦¬
import faiss
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI
from langchain_community.vectorstores import FAISS
from langchain.vectorstores import Chroma
from langchain.schema import Document
from langchain.prompts import ChatPromptTemplate
from langchain.schema.output_parser import StrOutputParser
from langchain.schema.runnable import RunnableParallel, RunnableLambda
from operator import itemgetter

from dotenv import load_dotenv
load_dotenv()

class FAISSRAGWithMemory:
    """FAISS RAG + ëŒ€í™” ë©”ëª¨ë¦¬ í†µí•© ì‹œìŠ¤í…œ"""
    
    def __init__(self, 
                 faiss_index_dir: str = "DocumentsLoader/educational_faiss_index",
                 memory_persist_dir: str = "./conversation_memory",
                 embedding_type: str = "huggingface"):
        
        print("ğŸ¤– FAISS RAG + ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œ ì´ˆê¸°í™”")
        
        self.faiss_index_dir = Path(faiss_index_dir)
        self.embedding_type = embedding_type
        
        # ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”
        self._initialize_embeddings()
        
        # LLM ëª¨ë¸ ì´ˆê¸°í™”
        self._initialize_llm()
        
        # FAISS ì¸ë±ìŠ¤ (ë¬¸ì„œ ê²€ìƒ‰ìš©)
        self.faiss_index = None
        
        # Chroma ë²¡í„°ìŠ¤í† ì–´ (ëŒ€í™” ë©”ëª¨ë¦¬ìš©)
        self.memory_store = Chroma(
            persist_directory=memory_persist_dir,
            embedding_function=self.embeddings
        )
        
        # í˜„ì¬ ì„¸ì…˜ ê´€ë¦¬
        self.current_session_id = datetime.now().strftime("%Y%m%d_%H%M%S")
        self.conversation_buffer = []
        
        # ì²´ì¸ ì„¤ì •
        self._setup_chains()
        
        print("   âœ… ì´ˆê¸°í™” ì™„ë£Œ")
    
    def _initialize_embeddings(self):
        """ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”"""
        if self.embedding_type == "gemini":
            try:
                api_key = os.getenv("GOOGLE_API_KEY")
                if not api_key:
                    raise Exception("GOOGLE_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•ŠìŒ")
                
                self.embeddings = GoogleGenerativeAIEmbeddings(
                    model="models/embedding-001",
                    google_api_key=api_key
                )
                print("   âœ… Gemini ì„ë² ë”© ë¡œë“œ ì™„ë£Œ")
                
            except Exception as e:
                print(f"   âš ï¸ Gemini ì„ë² ë”© ì‹¤íŒ¨: {e}")
                print("   ğŸ”„ HuggingFaceë¡œ ì „í™˜")
                self._load_huggingface_embeddings()
        else:
            self._load_huggingface_embeddings()
    
    def _load_huggingface_embeddings(self):
        """HuggingFace ì„ë² ë”© ë¡œë“œ"""
        self.embeddings = HuggingFaceEmbeddings(
            model_name="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2",
            model_kwargs={'device': 'cpu'},
            encode_kwargs={'normalize_embeddings': True}
        )
        self.embedding_type = "huggingface"
        print("   âœ… HuggingFace ì„ë² ë”© ë¡œë“œ ì™„ë£Œ")
    
    def _initialize_llm(self):
        """LLM ì´ˆê¸°í™”"""
        api_key = os.getenv("GOOGLE_API_KEY")
        if not api_key:
            raise Exception("GOOGLE_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ í•„ìš”í•©ë‹ˆë‹¤")
        
        self.llm = ChatGoogleGenerativeAI(
            model="gemini-2.0-flash-exp",
            google_api_key=api_key,
            temperature=0.7,
            max_output_tokens=2048,
            convert_system_message_to_human=True
        )
        print("   âœ… Gemini 2.0 Flash LLM ë¡œë“œ ì™„ë£Œ")
    
    def _setup_chains(self):
        """RAG + ë©”ëª¨ë¦¬ ì²´ì¸ êµ¬ì„±"""
        
        def search_documents(query: str) -> str:
            """FAISSì—ì„œ ë¬¸ì„œ ê²€ìƒ‰"""
            if not self.faiss_index or not hasattr(self.faiss_index, 'similarity_search_with_score'):
                return ""
            
            try:
                docs_and_scores = self.faiss_index.similarity_search_with_score(query, k=3)
                if docs_and_scores:
                    results = []
                    for doc, score in docs_and_scores:
                        results.append(f"[ë¬¸ì„œ] {doc.page_content}")
                    return "\n\n".join(results)
            except Exception:
                # FAISS ì¸ë±ìŠ¤ ë¬¸ì œê°€ ìˆì–´ë„ ì¡°ìš©íˆ ì²˜ë¦¬
                pass
            
            return ""
        
        def search_conversations(query: str) -> str:
            """ë©”ëª¨ë¦¬ì—ì„œ ëŒ€í™” ê²€ìƒ‰"""
            if not hasattr(self.memory_store, 'similarity_search'):
                return ""
                
            try:
                docs = self.memory_store.similarity_search(query, k=3)
                conversations = []
                for doc in docs:
                    if doc.metadata.get('type') == 'conversation':
                        conversations.append(f"[ì´ì „ëŒ€í™”] {doc.page_content}")
                return "\n\n".join(conversations)
            except Exception:
                # ë©”ëª¨ë¦¬ê°€ ë¹„ì–´ìˆê±°ë‚˜ ë¬¸ì œê°€ ìˆì–´ë„ ì¡°ìš©íˆ ì²˜ë¦¬
                return ""
        
        def get_recent_context(inputs) -> str:
            """ìµœê·¼ ëŒ€í™” ì»¨í…ìŠ¤íŠ¸"""
            if not self.conversation_buffer:
                return ""
            
            recent = self.conversation_buffer[-2:]  # ìµœê·¼ 2í„´
            context = []
            for turn in recent:
                context.append(f"ì‚¬ìš©ì: {turn['human']}")
                context.append(f"AI: {turn['ai']}")
            return "\n".join(context)
        
        # ë³‘ë ¬ ê²€ìƒ‰ ì²´ì¸
        self.search_chain = RunnableParallel({
            "query": itemgetter("query"),
            "documents": itemgetter("query") | RunnableLambda(search_documents),
            "conversations": itemgetter("query") | RunnableLambda(search_conversations),
            "recent_context": RunnableLambda(get_recent_context)
        })
        
        # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
        self.prompt = ChatPromptTemplate.from_template("""
ë‹¹ì‹ ì€ ë„ì›€ì´ ë˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.

ê²€ìƒ‰ëœ ë¬¸ì„œ:
{documents}

ì´ì „ ëŒ€í™” ê¸°ë¡:
{conversations}

ìµœê·¼ ëŒ€í™”:
{recent_context}

ì‚¬ìš©ì ì§ˆë¬¸: {query}

ë‹µë³€ ì§€ì¹¨:
1. ë¬¸ì„œ ë‚´ìš©ì´ ìˆìœ¼ë©´ ìš°ì„ ì ìœ¼ë¡œ í™œìš©
2. ì´ì „ ëŒ€í™”ê°€ ìˆìœ¼ë©´ ì¼ê´€ì„± ìœ ì§€
3. ìµœê·¼ ëŒ€í™” ë§¥ë½ ê³ ë ¤
4. í•œêµ­ì–´ë¡œ ëª…í™•í•˜ê²Œ ë‹µë³€

ë‹µë³€:
""")
        
        # ì „ì²´ ì²´ì¸
        self.rag_chain = (
            self.search_chain
            | self.prompt
            | self.llm
            | StrOutputParser()
        )
    
    def load_faiss_index(self) -> bool:
        """FAISS ì¸ë±ìŠ¤ ë¡œë“œ"""
        try:
            if not (self.faiss_index_dir / "index.faiss").exists():
                print(f"âŒ FAISS ì¸ë±ìŠ¤ ì—†ìŒ: {self.faiss_index_dir}")
                return False
            
            print("ğŸ“‚ FAISS ì¸ë±ìŠ¤ ë¡œë“œ ì¤‘...")
            self.faiss_index = FAISS.load_local(
                str(self.faiss_index_dir),
                self.embeddings,
                allow_dangerous_deserialization=True
            )
            print("   âœ… FAISS ì¸ë±ìŠ¤ ë¡œë“œ ì™„ë£Œ")
            
            # ì¸ë±ìŠ¤ ì •ë³´
            docs = list(self.faiss_index.docstore.values())
            print(f"   ğŸ“„ ì´ ë¬¸ì„œ: {len(docs)}ê°œ")
            
            return True
            
        except Exception as e:
            print(f"âŒ ì¸ë±ìŠ¤ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False
    
    def add_conversation_to_memory(self, human_msg: str, ai_msg: str, 
                                  importance_threshold: float = 5.0):
        """ëŒ€í™”ë¥¼ ë©”ëª¨ë¦¬ì— ì €ì¥"""
        
        # ì¤‘ìš”ë„ ê³„ì‚° (ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹±)
        importance = self._calculate_importance(human_msg, ai_msg)
        
        # í˜„ì¬ ì„¸ì…˜ ë²„í¼ì— ì¶”ê°€
        self.conversation_buffer.append({
            "human": human_msg,
            "ai": ai_msg,
            "importance": importance,
            "timestamp": datetime.now()
        })
        
        # ë²„í¼ í¬ê¸° ì œí•œ
        if len(self.conversation_buffer) > 10:
            self.conversation_buffer.pop(0)
        
        # ì¤‘ìš”í•œ ëŒ€í™”ë§Œ ë²¡í„° ìŠ¤í† ì–´ì— ì €ì¥
        if importance >= importance_threshold:
            conversation_text = f"ì‚¬ìš©ì: {human_msg}\nAI: {ai_msg}"
            metadata = {
                "type": "conversation",
                "session_id": self.current_session_id,
                "importance": importance,
                "timestamp": datetime.now().isoformat()
            }
            
            self.memory_store.add_texts([conversation_text], [metadata])
            self.memory_store.persist()
            print(f"ğŸ’¾ ëŒ€í™” ì €ì¥ë¨ (ì¤‘ìš”ë„: {importance:.1f})")
    
    def _calculate_importance(self, human_msg: str, ai_msg: str) -> float:
        """ëŒ€í™” ì¤‘ìš”ë„ ê³„ì‚°"""
        score = 3.0  # ê¸°ë³¸ ì ìˆ˜
        
        # ê¸¸ì´ ê¸°ë°˜
        if len(human_msg) > 50:
            score += 1.0
        
        # í‚¤ì›Œë“œ ê¸°ë°˜
        important_keywords = [
            "ë°°ìš°", "í•™ìŠµ", "ê³µë¶€", "ê¸°ì–µ", "ì„¤ëª…", "ë°©ë²•", "ì–´ë–»ê²Œ", 
            "ë¬´ì—‡", "ì–¸ì œ", "ì™œ", "í”„ë¡œì íŠ¸", "ê³„íš", "ì¤‘ìš”"
        ]
        
        for keyword in important_keywords:
            if keyword in human_msg or keyword in ai_msg:
                score += 0.5
        
        return min(score, 10.0)
    
    def chat(self, message: str) -> Dict[str, Any]:
        """ëŒ€í™” ì²˜ë¦¬"""
        print(f"\nğŸ” ì§ˆë¬¸: {message}")
        
        try:
            # RAG ì²´ì¸ìœ¼ë¡œ ë‹µë³€ ìƒì„±
            response = self.rag_chain.invoke({"query": message})
            
            # ë©”ëª¨ë¦¬ì— ì €ì¥
            self.add_conversation_to_memory(message, response)
            
            # ì†ŒìŠ¤ ì •ë³´ ìˆ˜ì§‘
            sources = self._get_sources(message)
            
            result = {
                "query": message,
                "answer": response,
                "sources": sources,
                "session_id": self.current_session_id,
                "timestamp": datetime.now().isoformat()
            }
            
            return result
            
        except Exception as e:
            print(f"âŒ ë‹µë³€ ìƒì„± ì‹¤íŒ¨: {e}")
            return {
                "query": message,
                "answer": f"ì£„ì†¡í•©ë‹ˆë‹¤. ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
                "sources": {"documents": [], "conversations": []},
                "session_id": self.current_session_id
            }
    
    def _get_sources(self, query: str) -> Dict[str, List]:
        """ê²€ìƒ‰ ì†ŒìŠ¤ ì •ë³´ ìˆ˜ì§‘"""
        sources = {"documents": [], "conversations": []}
        
        # ë¬¸ì„œ ì†ŒìŠ¤ (FAISS)
        if self.faiss_index and hasattr(self.faiss_index, 'similarity_search_with_score'):
            try:
                docs_and_scores = self.faiss_index.similarity_search_with_score(query, k=3)
                for doc, score in docs_and_scores:
                    sources["documents"].append({
                        "content": doc.page_content[:200] + "...",
                        "score": float(score),
                        "metadata": doc.metadata
                    })
            except Exception as e:
                # FAISS ì¸ë±ìŠ¤ê°€ ì—†ì–´ë„ ì •ìƒ ë™ì‘í•˜ë„ë¡ ì¡°ìš©íˆ ì²˜ë¦¬
                pass
        
        # ëŒ€í™” ì†ŒìŠ¤ (Chroma)
        try:
            if hasattr(self.memory_store, 'similarity_search'):
                conv_docs = self.memory_store.similarity_search(query, k=3)
                for doc in conv_docs:
                    if doc.metadata.get('type') == 'conversation':
                        sources["conversations"].append({
                            "content": doc.page_content[:200] + "...",
                            "metadata": doc.metadata
                        })
        except Exception as e:
            # ë©”ëª¨ë¦¬ê°€ ë¹„ì–´ìˆì–´ë„ ì •ìƒ ë™ì‘í•˜ë„ë¡ ì¡°ìš©íˆ ì²˜ë¦¬
            pass
        
        return sources
    
    def get_memory_stats(self) -> Dict[str, Any]:
        """ë©”ëª¨ë¦¬ í†µê³„"""
        try:
            # ì „ì²´ ë©”ëª¨ë¦¬ í•­ëª© ìˆ˜
            all_docs = self.memory_store.similarity_search("", k=1000)
            conversations = [d for d in all_docs if d.metadata.get('type') == 'conversation']
            
            return {
                "total_memory_items": len(all_docs),
                "conversation_items": len(conversations),
                "current_buffer_size": len(self.conversation_buffer),
                "faiss_documents": len(list(self.faiss_index.docstore.values())) if self.faiss_index else 0,
                "current_session": self.current_session_id
            }
        except Exception as e:
            return {"error": str(e)}
    
    def search_memory(self, query: str, k: int = 5) -> List[Dict]:
        """ë©”ëª¨ë¦¬ ê²€ìƒ‰"""
        try:
            docs = self.memory_store.similarity_search_with_score(query, k=k)
            results = []
            
            for doc, score in docs:
                results.append({
                    "content": doc.page_content,
                    "score": float(score),
                    "type": doc.metadata.get('type', 'unknown'),
                    "timestamp": doc.metadata.get('timestamp')
                })
            
            return results
        except Exception as e:
            print(f"ë©”ëª¨ë¦¬ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return []
    
    def start_new_session(self) -> str:
        """ìƒˆ ì„¸ì…˜ ì‹œì‘"""
        # ì´ì „ ì„¸ì…˜ ìš”ì•½ ì €ì¥ (ì˜µì…˜)
        if len(self.conversation_buffer) >= 3:
            self._save_session_summary()
        
        # ìƒˆ ì„¸ì…˜ ì‹œì‘
        self.current_session_id = datetime.now().strftime("%Y%m%d_%H%M%S")
        self.conversation_buffer = []
        
        print(f"ğŸ”„ ìƒˆ ì„¸ì…˜ ì‹œì‘: {self.current_session_id}")
        return self.current_session_id
    
    def _save_session_summary(self):
        """ì„¸ì…˜ ìš”ì•½ ì €ì¥"""
        try:
            full_conversation = "\n".join([
                f"ì‚¬ìš©ì: {turn['human']}\nAI: {turn['ai']}"
                for turn in self.conversation_buffer
            ])
            
            summary_prompt = f"ë‹¤ìŒ ëŒ€í™”ë¥¼ ê°„ë‹¨íˆ ìš”ì•½í•´ì£¼ì„¸ìš”:\n\n{full_conversation}"
            summary = self.llm.invoke(summary_prompt).content
            
            # ìš”ì•½ì„ ë©”ëª¨ë¦¬ì— ì €ì¥
            metadata = {
                "type": "session_summary",
                "session_id": self.current_session_id,
                "timestamp": datetime.now().isoformat(),
                "original_turns": len(self.conversation_buffer)
            }
            
            self.memory_store.add_texts([f"ì„¸ì…˜ ìš”ì•½: {summary}"], [metadata])
            self.memory_store.persist()
            
            print("ğŸ“ ì„¸ì…˜ ìš”ì•½ ì €ì¥ë¨")
            
        except Exception as e:
            print(f"ìš”ì•½ ì €ì¥ ì˜¤ë¥˜: {e}")
    
    def interactive_mode(self):
        """ëŒ€í™”í˜• ëª¨ë“œ"""
        print("\nğŸ¤– ëŒ€í™”í˜• FAISS RAG + ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œ")
        print("ëª…ë ¹ì–´: 'stats' (í†µê³„), 'search <ì§ˆë¬¸>' (ë©”ëª¨ë¦¬ ê²€ìƒ‰), 'new' (ìƒˆ ì„¸ì…˜), 'quit' (ì¢…ë£Œ)")
        print()
        
        while True:
            try:
                user_input = input("ì§ˆë¬¸: ").strip()
                
                if user_input.lower() == 'quit':
                    break
                elif user_input.lower() == 'stats':
                    stats = self.get_memory_stats()
                    print("\nğŸ“Š ì‹œìŠ¤í…œ í†µê³„:")
                    for key, value in stats.items():
                        print(f"   {key}: {value}")
                    print()
                elif user_input.lower() == 'new':
                    self.start_new_session()
                elif user_input.startswith('search '):
                    query = user_input[7:].strip()
                    results = self.search_memory(query)
                    print(f"\nğŸ” ë©”ëª¨ë¦¬ ê²€ìƒ‰ ê²°ê³¼ ({len(results)}ê°œ):")
                    for i, result in enumerate(results, 1):
                        print(f"   {i}. [{result['type']}] {result['content'][:100]}...")
                    print()
                elif user_input:
                    result = self.chat(user_input)
                    print(f"\nğŸ¤– ë‹µë³€:")
                    print("-" * 40)
                    print(result['answer'])
                    
                    # ì†ŒìŠ¤ ì •ë³´ ì¶œë ¥
                    sources = result['sources']
                    if sources['documents']:
                        print(f"\nğŸ“„ ì°¸ì¡° ë¬¸ì„œ: {len(sources['documents'])}ê°œ")
                    if sources['conversations']:
                        print(f"ğŸ’­ ê´€ë ¨ ëŒ€í™”: {len(sources['conversations'])}ê°œ")
                    print()
                
            except KeyboardInterrupt:
                print("\nğŸ‘‹ ì‹œìŠ¤í…œ ì¢…ë£Œ")
                break
            except Exception as e:
                print(f"ì˜¤ë¥˜: {e}")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    import sys
    
    # ëª…ë ¹í–‰ ì¸ìˆ˜ ì²˜ë¦¬
    embedding_type = "huggingface"
    if len(sys.argv) > 1:
        embedding_type = sys.argv[1].lower()
    
    print(f"ğŸ¤– FAISS RAG + ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œ (ì„ë² ë”©: {embedding_type})")
    
    try:
        # ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        rag_memory = FAISSRAGWithMemory(embedding_type=embedding_type)
        
        # FAISS ì¸ë±ìŠ¤ ë¡œë“œ
        if rag_memory.load_faiss_index():
            print("ğŸ‰ ì‹œìŠ¤í…œ ì¤€ë¹„ ì™„ë£Œ!")
            
            # ëŒ€í™”í˜• ëª¨ë“œ ì‹¤í–‰
            rag_memory.interactive_mode()
        else:
            print("âŒ FAISS ì¸ë±ìŠ¤ ë¡œë“œ ì‹¤íŒ¨")
            print("ğŸ’¡ ë¨¼ì € ì¸ë±ìŠ¤ë¥¼ êµ¬ì¶•í•´ì£¼ì„¸ìš”.")
            
    except Exception as e:
        print(f"âŒ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")

if __name__ == "__main__":
    main()
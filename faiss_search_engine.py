"""
FAISS HNSW ê²€ìƒ‰ ì—”ì§„
ì €ì¥ëœ FAISS ì¸ë±ìŠ¤ë¥¼ ë¡œë“œí•˜ì—¬ ìœ ì‚¬ë„ ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ëŠ” ì‹œìŠ¤í…œ
"""

import os
import json
from datetime import datetime
from pathlib import Path
from typing import List, Dict, Any, Tuple, Optional
import numpy as np

# FAISS ë¼ì´ë¸ŒëŸ¬ë¦¬
import faiss

# LangChain ê´€ë ¨ ë¼ì´ë¸ŒëŸ¬ë¦¬
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_google_genai import GoogleGenerativeAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain.schema import Document

from dotenv import load_dotenv
load_dotenv()

class FAISSSearchEngine:
    """
    FAISS HNSW ê²€ìƒ‰ ì—”ì§„ í´ë˜ìŠ¤
    ì €ì¥ëœ FAISS ì¸ë±ìŠ¤ë¥¼ ë¡œë“œí•˜ì—¬ ìœ ì‚¬ë„ ê²€ìƒ‰ ìˆ˜í–‰
    """
    
    def __init__(self, embedding_type: str = "huggingface"):
        """
        ê²€ìƒ‰ ì—”ì§„ ì´ˆê¸°í™”
        Args:
            embedding_type: "huggingface" ë˜ëŠ” "gemini"
        """
        print("ğŸ” FAISS ê²€ìƒ‰ ì—”ì§„ ì´ˆê¸°í™”")
        
        # íŒŒì¼ ê²½ë¡œ ì„¤ì •
        self.index_dir = Path("DocumentsLoader/educational_faiss_index")
        
        # ì„ë² ë”© íƒ€ì… ì„¤ì •
        self.embedding_type = embedding_type
        
        # HNSW ì„¤ì •
        self.hnsw_config = {
            'M': 16,
            'efConstruction': 100,
            'efSearch': 50,
            'metric': faiss.METRIC_INNER_PRODUCT
        }
        
        # ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”
        self._initialize_embeddings()
        
        # FAISS ì¸ë±ìŠ¤ ì´ˆê¸°í™”
        self.faiss_index = None
        
        print("   âœ… ê²€ìƒ‰ ì—”ì§„ ì´ˆê¸°í™” ì™„ë£Œ")
    
    def _initialize_embeddings(self):
        """ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”"""
        print("   ğŸ”„ ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™” ì¤‘...")
        
        if self.embedding_type == "gemini":
            try:
                # Gemini API í‚¤ í™•ì¸
                api_key = os.getenv("GOOGLE_API_KEY")
                if not api_key:
                    print("   âš ï¸ GOOGLE_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                    print("   ğŸ’¡ HuggingFace ì„ë² ë”©ìœ¼ë¡œ ìë™ ì „í™˜í•©ë‹ˆë‹¤.")
                    self._load_huggingface_embeddings()
                    return
                
                print("   ğŸ”‘ Gemini API í‚¤ í™•ì¸ë¨")
                
                # Gemini ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”
                self.embeddings = GoogleGenerativeAIEmbeddings(
                    model="models/embedding-001",
                    google_api_key=api_key,
                    task_type="retrieval_query",
                    title="Technical Analysis Document"
                )
                
                # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ë¡œ ì—°ê²° í™•ì¸
                test_embedding = self.embeddings.embed_query("test")
                if test_embedding and len(test_embedding) > 0:
                    print("   âœ… Gemini ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ë° í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
                else:
                    raise Exception("ì„ë² ë”© í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")
                    
            except Exception as e:
                error_msg = str(e)
                print(f"   âš ï¸ Gemini ì„ë² ë”© ë¡œë“œ ì‹¤íŒ¨: {error_msg}")
                
                # ì˜¤ë¥˜ ìœ í˜•ë³„ ì•ˆë‚´ ë©”ì‹œì§€
                if "invalid_grant" in error_msg or "Bad Request" in error_msg:
                    print("   ğŸ’¡ API í‚¤ ì¸ì¦ ì˜¤ë¥˜ì…ë‹ˆë‹¤. ë‹¤ìŒì„ í™•ì¸í•´ì£¼ì„¸ìš”:")
                    print("      - GOOGLE_API_KEYê°€ ì˜¬ë°”ë¥¸ì§€ í™•ì¸")
                    print("      - API í‚¤ê°€ Gemini APIì— ëŒ€í•œ ê¶Œí•œì´ ìˆëŠ”ì§€ í™•ì¸")
                    print("      - API í‚¤ê°€ ë§Œë£Œë˜ì§€ ì•Šì•˜ëŠ”ì§€ í™•ì¸")
                elif "timeout" in error_msg.lower():
                    print("   ğŸ’¡ ë„¤íŠ¸ì›Œí¬ íƒ€ì„ì•„ì›ƒì…ë‹ˆë‹¤. ì¸í„°ë„· ì—°ê²°ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
                elif "quota" in error_msg.lower():
                    print("   ğŸ’¡ API í• ë‹¹ëŸ‰ ì´ˆê³¼ì…ë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•˜ê±°ë‚˜ ë‹¤ë¥¸ API í‚¤ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.")
                else:
                    print("   ğŸ’¡ ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ì…ë‹ˆë‹¤. HuggingFace ì„ë² ë”©ìœ¼ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.")
                
                print("   ğŸ”„ HuggingFace ì„ë² ë”©ìœ¼ë¡œ ìë™ ì „í™˜ ì¤‘...")
                self._load_huggingface_embeddings()
        else:
            self._load_huggingface_embeddings()
    
    def _load_huggingface_embeddings(self):
        """HuggingFace ì„ë² ë”© ëª¨ë¸ ë¡œë“œ"""
        try:
            print("   ğŸ”„ HuggingFace ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì¤‘...")
            
            # ì—¬ëŸ¬ ëª¨ë¸ ì˜µì…˜ ì œê³µ
            model_options = [
                "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2",
                "sentence-transformers/all-MiniLM-L6-v2",
                "sentence-transformers/paraphrase-multilingual-mpnet-base-v2"
            ]
            
            for model_name in model_options:
                try:
                    print(f"   ğŸ” ëª¨ë¸ ì‹œë„ ì¤‘: {model_name}")
                    self.embeddings = HuggingFaceEmbeddings(
                        model_name=model_name,
                        model_kwargs={'device': 'cpu'},
                        encode_kwargs={'normalize_embeddings': True}
                    )
                    
                    # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸
                    test_embedding = self.embeddings.embed_query("test")
                    if test_embedding and len(test_embedding) > 0:
                        print(f"   âœ… HuggingFace ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {model_name}")
                        self.embedding_type = "huggingface"
                        return
                    else:
                        raise Exception("ì„ë² ë”© í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")
                        
                except Exception as e:
                    print(f"   âš ï¸ {model_name} ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
                    continue
            
            # ëª¨ë“  ëª¨ë¸ì´ ì‹¤íŒ¨í•œ ê²½ìš°
            raise Exception("ì‚¬ìš© ê°€ëŠ¥í•œ HuggingFace ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            
        except Exception as e:
            print(f"   âŒ HuggingFace ì„ë² ë”© ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
            print("   ğŸ’¡ ì˜¤í”„ë¼ì¸ ëª¨ë“œë¡œ ì „í™˜í•˜ê±°ë‚˜ ì¸í„°ë„· ì—°ê²°ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
            raise
    
    def load_index(self) -> bool:
        """ì €ì¥ëœ FAISS ì¸ë±ìŠ¤ ë¡œë“œ"""
        try:
            if not (self.index_dir / "index.faiss").exists():
                print(f"   âŒ FAISS ì¸ë±ìŠ¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {self.index_dir}")
                print("   ğŸ’¡ ë¨¼ì € 'faiss_index_builder.py'ë¥¼ ì‹¤í–‰í•˜ì—¬ ì¸ë±ìŠ¤ë¥¼ êµ¬ì¶•í•´ì£¼ì„¸ìš”.")
                return False
            
            print("ğŸ“‚ FAISS HNSW ì¸ë±ìŠ¤ ë¡œë“œ ì¤‘...")
            self.faiss_index = FAISS.load_local(
                str(self.index_dir),
                self.embeddings,
                allow_dangerous_deserialization=True  # ë¡œì»¬ì—ì„œ ìƒì„±í•œ íŒŒì¼ì´ë¯€ë¡œ ì•ˆì „
            )
            print("   âœ… FAISS ì¸ë±ìŠ¤ ë¡œë“œ ì™„ë£Œ")
            
            # ì¸ë±ìŠ¤ ì •ë³´ ì¶œë ¥
            self._print_index_info()
            
            return True
            
        except Exception as e:
            print(f"   âŒ ì¸ë±ìŠ¤ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
            return False
    
    def _print_index_info(self):
        """ì¸ë±ìŠ¤ ì •ë³´ ì¶œë ¥"""
        if not self.faiss_index:
            return
        
        print("\nğŸ“Š ì¸ë±ìŠ¤ ì •ë³´:")
        print("-" * 30)
        
        # ê¸°ë³¸ ì •ë³´
        print(f"   â€¢ ì„ë² ë”© ëª¨ë¸: {self.embedding_type}")
        print(f"   â€¢ ì¸ë±ìŠ¤ íƒ€ì…: FAISS HNSW")
        print(f"   â€¢ ë¡œë“œ ìœ„ì¹˜: {self.index_dir}")
        
        # HNSW ì •ë³´
        if hasattr(self.faiss_index.index, 'hnsw'):
            print(f"   â€¢ HNSW ë…¸ë“œ ìˆ˜: {self.faiss_index.index.hnsw.levels.size()}")
            print(f"   â€¢ HNSW ìµœëŒ€ ë ˆë²¨: {self.faiss_index.index.hnsw.max_level}")
            print(f"   â€¢ HNSW efSearch: {self.faiss_index.index.hnsw.efSearch}")
        
        # ë¬¸ì„œ ì •ë³´
        docs = list(self.faiss_index.docstore.values())
        if docs:
            technical_docs = sum(1 for doc in docs if doc.metadata.get('has_technical_content', False))
            print(f"   â€¢ ì´ ë¬¸ì„œ ìˆ˜: {len(docs)}")
            print(f"   â€¢ ê¸°ìˆ ì  ë‚´ìš© ë¬¸ì„œ: {technical_docs}")
            print(f"   â€¢ í‰ê·  ë¬¸ì„œ ê¸¸ì´: {sum(len(doc.page_content) for doc in docs) // len(docs)}ì")
    
    def search(self, query: str, k: int = 5) -> List[Tuple[Document, float]]:
        """
        ìœ ì‚¬ë„ ê²€ìƒ‰ ìˆ˜í–‰
        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬
            k: ë°˜í™˜í•  ê²°ê³¼ ìˆ˜
        Returns:
            ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ (ë¬¸ì„œ, ìœ ì‚¬ë„ ì ìˆ˜)
        """
        if not self.faiss_index:
            print("âŒ FAISS ì¸ë±ìŠ¤ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return []
        
        try:
            print(f"\nğŸ” ê²€ìƒ‰ ìˆ˜í–‰: '{query}'")
            print("-" * 40)
            
            # HNSW ê²€ìƒ‰ íŒŒë¼ë¯¸í„° ì„¤ì •
            if hasattr(self.faiss_index.index, 'hnsw'):
                self.faiss_index.index.hnsw.efSearch = self.hnsw_config['efSearch']
                print(f"   ğŸ”§ HNSW efSearch ì„¤ì •: {self.hnsw_config['efSearch']}")
            
            # ìœ ì‚¬ë„ ê²€ìƒ‰ ìˆ˜í–‰
            print("   ğŸ”„ ê²€ìƒ‰ ìˆ˜í–‰ ì¤‘...")
            
            # ì§ì ‘ FAISS ì¸ë±ìŠ¤ë¥¼ ì‚¬ìš©í•˜ì—¬ ê²€ìƒ‰
            try:
                # ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±
                query_embedding = self.embeddings.embed_query(query)
                query_vector = np.array([query_embedding], dtype=np.float32)
                
                # FAISS ê²€ìƒ‰ ìˆ˜í–‰
                distances, indices = self.faiss_index.index.search(query_vector, k)
                
                # ê²°ê³¼ êµ¬ì„±
                docs_and_scores = []
                for i, (distance, idx) in enumerate(zip(distances[0], indices[0])):
                    if idx != -1:  # ìœ íš¨í•œ ì¸ë±ìŠ¤ì¸ ê²½ìš°
                        doc = self.faiss_index.docstore[idx]
                        # ê±°ë¦¬ë¥¼ ìœ ì‚¬ë„ ì ìˆ˜ë¡œ ë³€í™˜ (ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê¸°ì¤€)
                        similarity_score = 1.0 - distance
                        docs_and_scores.append((doc, similarity_score))
                
                print(f"   âœ… {len(docs_and_scores)}ê°œ ê²°ê³¼ ë°œê²¬")
                
            except Exception as search_error:
                print(f"   âš ï¸ ì§ì ‘ ê²€ìƒ‰ ì‹¤íŒ¨: {str(search_error)}")
                print("   ğŸ”„ LangChain ë˜í¼ë¡œ ì¬ì‹œë„...")
                
                # LangChain ë˜í¼ë¡œ ì¬ì‹œë„
                docs_and_scores = self.faiss_index.similarity_search_with_score(
                    query, k=k
                )
            
            print(f"   âœ… {len(docs_and_scores)}ê°œ ê²°ê³¼ ë°œê²¬")
            
            # ê²°ê³¼ ì¶œë ¥
            for i, (doc, score) in enumerate(docs_and_scores, 1):
                print(f"\n   ğŸ“„ ê²°ê³¼ {i}:")
                print(f"      - ìœ ì‚¬ë„ ì ìˆ˜: {score:.4f}")
                print(f"      - í˜ì´ì§€: {doc.metadata.get('page', 'N/A')}")
                print(f"      - ì²­í¬ í¬ê¸°: {doc.metadata.get('chunk_size', 'N/A')}ì")
                print(f"      - ê¸°ìˆ ì  ë‚´ìš©: {'âœ…' if doc.metadata.get('has_technical_content', False) else 'âŒ'}")
                print(f"      - ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°: {doc.page_content[:100]}...")
            
            return docs_and_scores
            
        except Exception as e:
            print(f"   âŒ ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}")
            return []
    
    def save_search_results(self, results: List[Tuple[Document, float]], query: str):
        """ê²€ìƒ‰ ê²°ê³¼ ì €ì¥"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"search_results_{timestamp}.json"
        
        try:
            search_data = {
                'query': query,
                'embedding_type': self.embedding_type,
                'timestamp': datetime.now().isoformat(),
                'total_results': len(results),
                'results': []
            }
            
            for doc, score in results:
                result_item = {
                    'score': float(score),
                    'page': doc.metadata.get('page', 'N/A'),
                    'chunk_id': doc.metadata.get('chunk_id', 'N/A'),
                    'chunk_size': doc.metadata.get('chunk_size', 'N/A'),
                    'has_technical_content': doc.metadata.get('has_technical_content', False),
                    'content': doc.page_content,
                    'metadata': doc.metadata
                }
                search_data['results'].append(result_item)
            
            output_path = Path("DocumentsLoader/search_results") / filename
            output_path.parent.mkdir(exist_ok=True)
            
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(search_data, f, ensure_ascii=False, indent=2)
            
            print(f"   âœ… ê²€ìƒ‰ ê²°ê³¼ ì €ì¥: {output_path}")
            
        except Exception as e:
            print(f"   âŒ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {str(e)}")
    
    def interactive_search(self):
        """ëŒ€í™”í˜• ê²€ìƒ‰ ëª¨ë“œ"""
        print("\nğŸ” ëŒ€í™”í˜• ê²€ìƒ‰ ëª¨ë“œ")
        print("=" * 50)
        print("ì‚¬ìš© ê°€ëŠ¥í•œ ëª…ë ¹ì–´:")
        print("  - ê²€ìƒ‰ì–´ë§Œ ì…ë ¥: ì§ì ‘ ê²€ìƒ‰ (ì˜ˆ: 'RSI', 'ë³¼ë¦°ì €ë°´ë“œ')")
        print("  - 'search <ê²€ìƒ‰ì–´>': ëª…ì‹œì  ê²€ìƒ‰ ëª…ë ¹")
        print("  - 'info': ì¸ë±ìŠ¤ ì •ë³´")
        print("  - 'quit': ì¢…ë£Œ")
        print(f"\ní˜„ì¬ ì„ë² ë”© ëª¨ë¸: {self.embedding_type}")
        print()
        
        while True:
            try:
                command = input("ê²€ìƒ‰ ëª…ë ¹ì–´ ì…ë ¥: ").strip()
                
                if command.lower() == 'quit':
                    break
                elif command.lower() == 'info':
                    self._print_index_info()
                elif command.startswith('search '):
                    # ëª…ì‹œì  search ëª…ë ¹ì–´ ì²˜ë¦¬
                    query = command[7:].strip()
                    if query:
                        results = self.search(query)
                        if results:
                            self.save_search_results(results, query)
                    else:
                        print("   âŒ ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                elif command:
                    # ë‹¨ìˆœ ê²€ìƒ‰ì–´ë¡œ ì²˜ë¦¬ (search ì ‘ë‘ì‚¬ ì—†ì´)
                    results = self.search(command)
                    if results:
                        self.save_search_results(results, command)
                    else:
                        print("   âŒ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    print("   âŒ ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                
                print()
                
            except KeyboardInterrupt:
                print("\nğŸ‘‹ ê²€ìƒ‰ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                break
            except Exception as e:
                print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
    
    def batch_search(self, queries: List[str], k: int = 5) -> Dict[str, List[Tuple[Document, float]]]:
        """
        ë°°ì¹˜ ê²€ìƒ‰ ìˆ˜í–‰
        Args:
            queries: ê²€ìƒ‰ ì¿¼ë¦¬ ë¦¬ìŠ¤íŠ¸
            k: ê° ì¿¼ë¦¬ë‹¹ ë°˜í™˜í•  ê²°ê³¼ ìˆ˜
        Returns:
            ì¿¼ë¦¬ë³„ ê²€ìƒ‰ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        if not self.faiss_index:
            print("âŒ FAISS ì¸ë±ìŠ¤ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return {}
        
        print(f"\nğŸ” ë°°ì¹˜ ê²€ìƒ‰ ìˆ˜í–‰: {len(queries)}ê°œ ì¿¼ë¦¬")
        print("-" * 40)
        
        results = {}
        for i, query in enumerate(queries, 1):
            print(f"   ğŸ“ ì¿¼ë¦¬ {i}/{len(queries)}: '{query}'")
            query_results = self.search(query, k)
            results[query] = query_results
            
            if query_results:
                print(f"      âœ… {len(query_results)}ê°œ ê²°ê³¼ ë°œê²¬")
            else:
                print(f"      âŒ ê²°ê³¼ ì—†ìŒ")
        
        return results

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    import sys
    
    # ëª…ë ¹í–‰ ì¸ìˆ˜ë¡œ ì„ë² ë”© íƒ€ì… ì„ íƒ
    embedding_type = "huggingface"
    if len(sys.argv) > 1:
        embedding_type = sys.argv[1].lower()
    
    if embedding_type not in ["huggingface", "gemini"]:
        print("âŒ ì§€ì›í•˜ì§€ ì•ŠëŠ” ì„ë² ë”© íƒ€ì…ì…ë‹ˆë‹¤. 'huggingface' ë˜ëŠ” 'gemini'ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.")
        return
    
    print(f"ğŸ” FAISS ê²€ìƒ‰ ì—”ì§„ - ì„ë² ë”© ëª¨ë¸: {embedding_type}")
    
    # ê²€ìƒ‰ ì—”ì§„ ì´ˆê¸°í™”
    search_engine = FAISSSearchEngine(embedding_type=embedding_type)
    
    # ì¸ë±ìŠ¤ ë¡œë“œ
    if search_engine.load_index():
        print("\nğŸ‰ ê²€ìƒ‰ ì—”ì§„ ì¤€ë¹„ ì™„ë£Œ!")
        
        # ëŒ€í™”í˜• ê²€ìƒ‰ ëª¨ë“œ ì‹¤í–‰
        search_engine.interactive_search()
        
    else:
        print("âŒ ê²€ìƒ‰ ì—”ì§„ ì´ˆê¸°í™”ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        print("ğŸ’¡ ë¨¼ì € 'faiss_index_builder.py'ë¥¼ ì‹¤í–‰í•˜ì—¬ ì¸ë±ìŠ¤ë¥¼ êµ¬ì¶•í•´ì£¼ì„¸ìš”.")

if __name__ == "__main__":
    main() 